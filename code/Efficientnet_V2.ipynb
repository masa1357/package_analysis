{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## signate 画像分類コンペ(2クラス)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インポート\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初期処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'C:\\\\Users\\\\zigza\\\\GitFile\\\\signate\\\\package_analysis\\\\'\n",
    "DATA_PATH = BASE_PATH + 'datasets\\\\'\n",
    "TRAIN_PATH = DATA_PATH + 'train\\\\'\n",
    "TEST_PATH = DATA_PATH + 'test\\\\'\n",
    "OUT_PATH = BASE_PATH + 'out\\\\'\n",
    "# C:\\\\Users\\\\zigza\\\\GitFile\\\\signate\\\\package_analysis\\\\train.csv\n",
    "# C:\\Users\\zigza\\GitFile\\signate\\package_analysis\\datasets\\train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name  label\n",
       "0   0000.png      0\n",
       "1   0001.png      1\n",
       "2   0002.png      1\n",
       "3   0003.png      1\n",
       "4   0004.png      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seedの固定\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 0\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.img_path = TRAIN_PATH\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 画像を読みこんで、指定の方法でtransform\n",
    "        img_name = os.path.join(self.img_path, self.file_list.iloc[index,0])\n",
    "        img = Image.open(img_name)\n",
    "        img_transformed = self.transform(img)\n",
    "        label = int(self.file_list.iloc[index,1])\n",
    "\n",
    "        return img_transformed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_df, val_df, test_df, img_size=224,\n",
    "                 mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),\n",
    "                 batch_size=16):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # train時、val/test時の前処理をそれぞれ定義\n",
    "        self.train_transforms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(img_size, scale=(0.5, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "        self.val_test_transforms = transforms.Compose([\n",
    "            transforms.Resize(img_size),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    # データのダウンロードなどを行う場合は定義、今回は不要\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    # Trainer.fit()ではtrain/valのDatasetを、Trainer.test()ではtestのDatasetを生成\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = MyDataset(self.train_df, self.train_transforms)\n",
    "            self.val_dataset = MyDataset(self.val_df, self.val_test_transforms)\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_dataset = MyDataset(self.test_df, self.val_test_transforms)\n",
    "\n",
    "    # こちらもTrainer.fit()ではtrain/valのDataLoaderを、Trainer.test()ではtestのDataLoaderを生成\n",
    "    # trainはshuffleあり、val/testはshuffleなし\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seedを固定\n",
    "fix_seed(SEED)\n",
    "\n",
    "#train_df内のデータを7:2:1の割合でval_df,test_dfに分割\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.3, shuffle=True, random_state=SEED)\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.33, shuffle=True, random_state=SEED)\n",
    "\n",
    "# インスタンスを作成\n",
    "data_module = CreateDataModule(train_df,val_df,test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name, n_classes, lr=0.0001, criterion=torch.nn.CrossEntropyLoss()):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # timmで学習済みモデルをダウンロードし、classifier部分を付替え\n",
    "        # n_classesにはラベルの件数を渡す（今回はアリとハチの2つなので2）\n",
    "        self.model = timm.create_model(model_name, pretrained=True)\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, n_classes)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.criterion = criterion\n",
    "        self.outputs = []\n",
    "\n",
    "    # 順伝搬\n",
    "    def forward(self, imgs, labels=None):\n",
    "        preds = self.model(imgs)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(preds, labels)\n",
    "        return loss, preds\n",
    "\n",
    "    # trainのミニバッチに対して行う処理\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        loss, preds = self.forward(imgs=imgs, labels=labels)\n",
    "        return {'loss': loss, 'batch_preds': preds.detach(), 'batch_labels': labels.detach()}\n",
    "\n",
    "    # validation、testでもtrain_stepと同じ処理を行う\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        result = self.training_step(batch, batch_idx)\n",
    "        self.outputs.append(result)\n",
    "        return result\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        result = self.testing_step(batch, batch_idx)\n",
    "        self.outputs.append(result)\n",
    "        return result\n",
    "\n",
    "    # epoch終了時にvalidationのlossとaccuracyを記録\n",
    "    def on_validation_epoch_end(self):\n",
    "\n",
    "        # loss計算\n",
    "        epoch_preds = torch.cat([x['batch_preds'] for x in self.outputs])\n",
    "        epoch_labels = torch.cat([x['batch_labels'] for x in self.outputs])\n",
    "        epoch_loss = self.criterion(epoch_preds, epoch_labels)\n",
    "        self.log(f\"val_loss\", epoch_loss, logger=True)\n",
    "\n",
    "        # accuracy計算\n",
    "        num_correct = (epoch_preds.argmax(dim=1) == epoch_labels).sum().item()\n",
    "        epoch_accuracy = num_correct / len(epoch_labels)\n",
    "        self.log(f\"val_accuracy\", epoch_accuracy, logger=True)\n",
    "        self.outputs = []\n",
    "\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        ret = self.validation_epoch_end(self.outputs, \"test\")\n",
    "        self.outputs = []\n",
    "        return ret\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(lr=self.lr, params=self.model.parameters())\n",
    "        scheduler = {'scheduler': optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)}\n",
    "        return [optimizer], [scheduler]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:197: UserWarning: Attribute 'criterion' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# モデルインスタンスの作成\n",
    "model = ImageClassifier(model_name=\"efficientnet_b0\", n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# EarlyStoppingの設定\n",
    "# 3epochで'val_loss'が0.05以上減少しなければ学習をストップ\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.05, patience=3, mode='min')\n",
    "\n",
    "# モデルの保存先\n",
    "# epoch数に応じて、「epoch=0.ckpt」のような形で保存\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename='{epoch}', monitor='val_loss', mode='min', verbose=True)\n",
    "\n",
    "# trainerの設定\n",
    "trainer = pl.Trainer(max_epochs=30,\n",
    "                     devices=1,\n",
    "                     callbacks=[checkpoint_callback, early_stop_callback],\n",
    "                     log_every_n_steps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | EfficientNet     | 4.0 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.040    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a17046caf24a6f986beffb9ad762b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1833a912ebe4a7fa085184fb64edc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3245b0353c5b4503af6b0f021443eaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 96: 'val_loss' reached 0.56940 (best 0.56940), saving model to 'c:\\\\Users\\\\zigza\\\\GitFile\\\\signate\\\\package_analysis\\\\code\\\\lightning_logs\\\\version_1\\\\checkpoints\\\\epoch=0.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab479a6a796a4bd59a1623d5071b326a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 192: 'val_loss' reached 0.51173 (best 0.51173), saving model to 'c:\\\\Users\\\\zigza\\\\GitFile\\\\signate\\\\package_analysis\\\\code\\\\lightning_logs\\\\version_1\\\\checkpoints\\\\epoch=1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa4a1cf7cb14f6da0c9d3ad8d72e20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 288: 'val_loss' reached 0.45891 (best 0.45891), saving model to 'c:\\\\Users\\\\zigza\\\\GitFile\\\\signate\\\\package_analysis\\\\code\\\\lightning_logs\\\\version_1\\\\checkpoints\\\\epoch=2.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffec21f88514f5f85c6114f912b0dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 384: 'val_loss' reached 0.42204 (best 0.42204), saving model to 'c:\\\\Users\\\\zigza\\\\GitFile\\\\signate\\\\package_analysis\\\\code\\\\lightning_logs\\\\version_1\\\\checkpoints\\\\epoch=3.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbd6c5028dc4590a05120c56398a6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 480: 'val_loss' reached 0.40877 (best 0.40877), saving model to 'c:\\\\Users\\\\zigza\\\\GitFile\\\\signate\\\\package_analysis\\\\code\\\\lightning_logs\\\\version_1\\\\checkpoints\\\\epoch=4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb06278a8844431990c569e568b57f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 576: 'val_loss' reached 0.39721 (best 0.39721), saving model to 'c:\\\\Users\\\\zigza\\\\GitFile\\\\signate\\\\package_analysis\\\\code\\\\lightning_logs\\\\version_1\\\\checkpoints\\\\epoch=5.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18afd744aac041f68e7daf2480a71d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 672: 'val_loss' reached 0.38249 (best 0.38249), saving model to 'c:\\\\Users\\\\zigza\\\\GitFile\\\\signate\\\\package_analysis\\\\code\\\\lightning_logs\\\\version_1\\\\checkpoints\\\\epoch=6.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3490399c80f748a4b92574ba9a522919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 768: 'val_loss' was not in top 1\n"
     ]
    }
   ],
   "source": [
    "# gpuを設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 訓練開始\n",
    "data_module.setup('fit')\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at c:\\Users\\zigza\\GitFile\\signate\\package_analysis\\code\\lightning_logs\\version_1\\checkpoints\\epoch=6.ckpt\n",
      "Loaded model weights from the checkpoint at c:\\Users\\zigza\\GitFile\\signate\\package_analysis\\code\\lightning_logs\\version_1\\checkpoints\\epoch=6.ckpt\n",
      "c:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:438: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27dc4411af1449e9a1d17718c38dff86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "ImageClassifier.on_test_epoch_end() missing 1 required positional argument: 'outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zigza\\GitFile\\signate\\package_analysis\\code\\Efficientnet_V2.ipynb セル 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zigza/GitFile/signate/package_analysis/code/Efficientnet_V2.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data_module \u001b[39m=\u001b[39m CreateDataModule(train_df,val_df,test_df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zigza/GitFile/signate/package_analysis/code/Efficientnet_V2.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data_module\u001b[39m.\u001b[39msetup(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zigza/GitFile/signate/package_analysis/code/Efficientnet_V2.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtest(datamodule\u001b[39m=\u001b[39;49mdata_module,ckpt_path\u001b[39m=\u001b[39;49mcheckpoint_callback\u001b[39m.\u001b[39;49mbest_model_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zigza/GitFile/signate/package_analysis/code/Efficientnet_V2.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m result\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:742\u001b[0m, in \u001b[0;36mTrainer.test\u001b[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m    741\u001b[0m _verify_strategy_supports_compile(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[1;32m--> 742\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    743\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[0;32m    744\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:785\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(model, test_dataloaders\u001b[39m=\u001b[39mdataloaders, datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[0;32m    782\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    783\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    784\u001b[0m )\n\u001b[1;32m--> 785\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    786\u001b[0m \u001b[39m# remove the tensors from the test results\u001b[39;00m\n\u001b[0;32m    787\u001b[0m results \u001b[39m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1016\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mrun-stage\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluating:\n\u001b[1;32m-> 1016\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1017\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m   1018\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[0;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:122\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_dataloader_outputs()\n\u001b[1;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_run_end()\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:244\u001b[0m, in \u001b[0;36m_EvaluationLoop.on_run_end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39m_evaluation_epoch_end()\n\u001b[0;32m    243\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_evaluation_epoch_end()\n\u001b[0;32m    246\u001b[0m logged_outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logged_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logged_outputs, []  \u001b[39m# free memory\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39m# include any logged outputs on epoch_end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:326\u001b[0m, in \u001b[0;36m_EvaluationLoop._on_evaluation_epoch_end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    324\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_epoch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_epoch_end\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(trainer, hook_name)\n\u001b[1;32m--> 326\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(trainer, hook_name)\n\u001b[0;32m    328\u001b[0m trainer\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mon_epoch_end()\n",
      "File \u001b[1;32mc:\\Users\\zigza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:145\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[0;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 145\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    147\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    148\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "\u001b[1;31mTypeError\u001b[0m: ImageClassifier.on_test_epoch_end() missing 1 required positional argument: 'outputs'"
     ]
    }
   ],
   "source": [
    "# 精度検証\n",
    "data_module = CreateDataModule(train_df,val_df,test_df)\n",
    "data_module.setup('test')\n",
    "result = trainer.test(datamodule=data_module,ckpt_path=checkpoint_callback.best_model_path)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboardでの確認\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir C:/Users/zigza/GitFile/signate/package_analysis/code/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最良モデルの保存\n",
    "best_model = ImageClassifier.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "\n",
    "with open('./best_model.pkl', mode='wb') as fp:\n",
    "    pickle.dump(best_model, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
